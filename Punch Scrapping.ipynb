{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchKeyword = \"MTN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site= f\"https://punchng.com/search/{searchKeyword}\"\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('punch.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date')]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list = []\n",
    "major = soup.find_all(\"h2\", {\"class\": \"seg-title\"})        \n",
    "for i in range (len(major)):\n",
    "    brand_name = searchKeyword\n",
    "    try:\n",
    "        Headline = soup.find_all(\"h2\", {\"class\": \"seg-title\"})\n",
    "        Headline = Headline[i].text\n",
    "        #print(f\"Headline: {Headline}\")\n",
    "    except:\n",
    "        print(None)\n",
    "    try:\n",
    "        Brief_body = soup.find_all(\"div\", {\"class\": \"seg-summary\"})\n",
    "        Brief_body = Brief_body[i].text\n",
    "        #print(f\"Brief_body: {Brief_body}\")\n",
    "    except:\n",
    "        print(None)\n",
    "    try:\n",
    "        Report_date = soup.find_all(\"div\", {\"class\": \"seg-time\"})            \n",
    "        Report_date = Report_date[i].text\n",
    "        #print(f\"Report_date: {Report_date}\")\n",
    "    except:\n",
    "        print(None)\n",
    "    \n",
    "    entry = [(brand_name, Headline, Brief_body, Report_date)]\n",
    "    list.append(Headline)\n",
    "    obj.writerows(entry)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read(\"punch.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Punch comment section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import re\n",
    "patn = '\\w+'\n",
    "\n",
    "for i in range(len(list)):\n",
    "    #remove punctuations\n",
    "    list[i] = re.sub(r'[^\\w\\s]','',list[i])\n",
    "    \n",
    "    #insert hyphens\n",
    "    list[i] = re.sub(r\"\\s+\", '-', list[i])\n",
    "    \n",
    "    #change the headline to lowercase\n",
    "    list[i] = list[i].lower()\n",
    "    \n",
    "    #open the main page for this headline\n",
    "    url = f'https://punchng.com/{list[i]}/'\n",
    "    \n",
    "    #get comment section soup\n",
    "    comment_req = Request('https://punchng.com/gsm-tax-mtn-glo-airtel-9mobile-subscribers-others-to-pay-extra-n261bn/',headers=hdr)\n",
    "    comment_page = urlopen(comment_req)\n",
    "    comment_soup = BeautifulSoup(comment_page)\n",
    "    \n",
    "\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment_soup_new = comment_soup.find_all(\"ul\",)\n",
    "comment_soup_new = comment_soup_new[0].text\n",
    "print(f\"Review: {comment_soup_new}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping The Nation Newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = f'https://thenationonlineng.net/?s={searchKeyword}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://thenationonlineng.net/?s=MTN'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "csvfile = open('Nation.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date', 'Url_link')]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "major = soup.find_all(\"h3\", {\"class\": \"jeg_post_title\"})\n",
    "\n",
    "for i in range (len(major)):\n",
    "    brand_name = searchKeyword\n",
    "    try:\n",
    "        Headline = soup.find_all(\"h3\", {\"class\": \"jeg_post_title\"})\n",
    "        Headline = Headline[i].text.strip()\n",
    "        if searchKeyword not in Headline:\n",
    "            break\n",
    "        #print(f\"Headline: {Headline}\")\n",
    "    except:\n",
    "        print(None)\n",
    "    try:\n",
    "        Brief_body = soup.find_all(\"div\", {\"class\": \"jeg_post_excerpt\"})\n",
    "        Brief_body = Brief_body[i].text.strip()\n",
    "        #print(f\"Headline: {Headline}\")\n",
    "    except:\n",
    "        print(\"me\")\n",
    "    try:\n",
    "        Report_date = soup.find_all(\"div\", {\"class\": \"jeg_meta_date\"})            \n",
    "        Report_date = Report_date[i].text.strip()\n",
    "        #print(f\"Report_date: {Report_date}\")\n",
    "    except:\n",
    "        print(None)\n",
    "    \n",
    "    #remove punctuations\n",
    "    Headline_link = re.sub(r'[^\\w\\s]','',Headline)\n",
    "    #insert hyphens\n",
    "    Headline_link = re.sub(r\"\\s+\", '-', Headline_link)\n",
    "    #change the headline to lowercase\n",
    "    Headline_link = Headline_link.lower()\n",
    "    #open the main page for this headline\n",
    "    url = f'https://thenationonlineng.net/{Headline_link}/'\n",
    "    \n",
    "    entry = [(brand_name, Headline, Brief_body, Report_date, url)]\n",
    "    list.append(Headline_link)\n",
    "    obj.writerows(entry)\n",
    "csvfile.close()\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Nation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Brief_body</th>\n",
       "      <th>Report_Date</th>\n",
       "      <th>Url_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Banks: we didn’t ask MTN to charge for USSD</td>\n",
       "      <td>By Lucas Ajanaku Commercial banks on Monday de...</td>\n",
       "      <td>October 22, 2019</td>\n",
       "      <td>https://thenationonlineng.net/banks-we-didnt-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTN</td>\n",
       "      <td>NCC stops MTN from charging customers N4 for USSD</td>\n",
       "      <td>Lucas Ajanaku and Blessing Olaifa   The Federa...</td>\n",
       "      <td>October 21, 2019</td>\n",
       "      <td>https://thenationonlineng.net/ncc-stops-mtn-fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTN</td>\n",
       "      <td>FG suspends MTN’s N4 USSD charges</td>\n",
       "      <td>By Blessing Olaifa, Abuja The federal governme...</td>\n",
       "      <td>October 20, 2019</td>\n",
       "      <td>https://thenationonlineng.net/fg-suspends-mtns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Court passes death sentence on killer of MTN s...</td>\n",
       "      <td>By Adekunle Jimoh, Ilorin Kwara state High Cou...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>https://thenationonlineng.net/court-passes-dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTN</td>\n",
       "      <td>MTN takes intervention to 510 communities</td>\n",
       "      <td>From Blessing Olaifa, Abuja No fewer than 510 ...</td>\n",
       "      <td>October 14, 2019</td>\n",
       "      <td>https://thenationonlineng.net/mtn-takes-interv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand_name                                           Headline  \\\n",
       "0        MTN        Banks: we didn’t ask MTN to charge for USSD   \n",
       "1        MTN  NCC stops MTN from charging customers N4 for USSD   \n",
       "2        MTN                  FG suspends MTN’s N4 USSD charges   \n",
       "3        MTN  Court passes death sentence on killer of MTN s...   \n",
       "4        MTN          MTN takes intervention to 510 communities   \n",
       "\n",
       "                                          Brief_body       Report_Date  \\\n",
       "0  By Lucas Ajanaku Commercial banks on Monday de...  October 22, 2019   \n",
       "1  Lucas Ajanaku and Blessing Olaifa   The Federa...  October 21, 2019   \n",
       "2  By Blessing Olaifa, Abuja The federal governme...  October 20, 2019   \n",
       "3  By Adekunle Jimoh, Ilorin Kwara state High Cou...  October 17, 2019   \n",
       "4  From Blessing Olaifa, Abuja No fewer than 510 ...  October 14, 2019   \n",
       "\n",
       "                                            Url_link  \n",
       "0  https://thenationonlineng.net/banks-we-didnt-a...  \n",
       "1  https://thenationonlineng.net/ncc-stops-mtn-fr...  \n",
       "2  https://thenationonlineng.net/fg-suspends-mtns...  \n",
       "3  https://thenationonlineng.net/court-passes-dea...  \n",
       "4  https://thenationonlineng.net/mtn-takes-interv...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = f'https://guardian.ng/?s={searchKeyword}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://guardian.ng/?s=MTN'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = \"MTN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('Guardian.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date', 'Url_link')]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "major = soup.find_all(\"div\", {\"class\": \"headline\"})\n",
    "for i in range(len(major)):\n",
    "    \n",
    "    #Get headline\n",
    "    try:\n",
    "        Headline = soup.find_all(\"div\", {\"class\": \"headline\"})\n",
    "        Headline = Headline[i].find_all(\"span\", {\"class\": \"title\"})[0].text\n",
    "        Headline = BeautifulSoup(Headline, \"lxml\").text\n",
    "        Headline_write = Headline\n",
    "        if searchKeyword not in Headline:\n",
    "            break\n",
    "    except:\n",
    "        Headline = \"Nan\"\n",
    "        Headline_write = \"Nan\"\n",
    "   \n",
    "    #Get first paragraph as text summary\n",
    " \n",
    "    #remove full stop inbetween figures in the link\n",
    "    index = 0\n",
    "    fullStopIndex = []\n",
    "    for char in Headline:\n",
    "        if index != 0  and char is '.'and Headline[index-1].isdigit and Headline[index+1].isdigit:\n",
    "            fullStopIndex.append(Headline[index-1])\n",
    "            fullStopIndex.append(Headline[index+1])\n",
    "            Headline = Headline.replace(Headline[index],\"-\",1)\n",
    "        index = index + 1\n",
    "   \n",
    "    \n",
    "    if Headline == \"Nan\":\n",
    "        url == \"Nan\"\n",
    "    else:\n",
    "        #replace hyphenes with whitespaces\n",
    "        Headline_link  = Headline.replace('-', ' ')\n",
    "\n",
    "        #remove punctuations\n",
    "\n",
    "        pattern = r'[^\\w\\s]'\n",
    "        pattern = pattern.replace(\"-\", \"\")\n",
    "        Headline_link = re.sub(pattern,'',Headline_link)\n",
    "        #insert hyphens\n",
    "        Headline_link = re.sub(r\"\\s+\", '-', Headline_link)\n",
    "        #change the headline to lowercase\n",
    "        Headline_link = Headline_link.lower()\n",
    "    \n",
    "        if fullStopIndex != []:\n",
    "            index = Headline_link.find(fullStopIndex[0])\n",
    "            if Headline_link.find(fullStopIndex[1]) == index+1:\n",
    "                Headline_link = Headline_link[:index+1] + '-' + Headline_link[index+1:]\n",
    "        \n",
    "       \n",
    "        #open the main page for this headline\n",
    "        url = f'https://guardian.ng/news/{Headline_link}/'\n",
    "    \n",
    "    \n",
    "        req = Request(url,headers=hdr)\n",
    "        page = urlopen(req)\n",
    "        soup_2 = BeautifulSoup(page)\n",
    "    \n",
    "        Brief_body = soup_2.find_all(\"article\")\n",
    "        Brief_body = Brief_body[0].find_all(\"p\")[2].text\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    #Get report Date\n",
    "    try:\n",
    "        Report_date = soup.find_all(\"div\", {\"class\": \"meta\"})\n",
    "        Report_date = Report_date[i].find_all(\"span\", {\"class\": \"age\"})[0].text\n",
    "    except: Report_date = \"Nan\"\n",
    "    \n",
    "    entry = [(brand_name, Headline_write, Brief_body, Report_date, url)]\n",
    "    #list.append(url)\n",
    "    obj.writerows(entry)\n",
    "csvfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Guardian.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Brief_body</th>\n",
       "      <th>Report_Date</th>\n",
       "      <th>Url_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTN</td>\n",
       "      <td>FG orders MTN, others to suspend planned USSD ...</td>\n",
       "      <td>A few telecommunications network service provi...</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>https://guardian.ng/news/fg-orders-mtn-others-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTN</td>\n",
       "      <td>CBN awards MTN subsidiary licence to provide f...</td>\n",
       "      <td>MTN Nigeria’s CEO Ferdi Moolman disclosed that...</td>\n",
       "      <td>30 Jul</td>\n",
       "      <td>https://guardian.ng/news/cbn-awards-mtn-subsid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTN</td>\n",
       "      <td>EFCC operatives visit MTN office, quiz management</td>\n",
       "      <td>Claims of manipulations, irregularities and sc...</td>\n",
       "      <td>25 May</td>\n",
       "      <td>https://guardian.ng/news/efcc-operatives-visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Ernest Ndukwe brings new magnetism to MTN, ind...</td>\n",
       "      <td>Ndukwe, the father of modern telecommunication...</td>\n",
       "      <td>16 Aug</td>\n",
       "      <td>https://guardian.ng/news/ernest-ndukwe-brings-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand_name                                           Headline  \\\n",
       "0        MTN  FG orders MTN, others to suspend planned USSD ...   \n",
       "1        MTN  CBN awards MTN subsidiary licence to provide f...   \n",
       "2        MTN  EFCC operatives visit MTN office, quiz management   \n",
       "3        MTN  Ernest Ndukwe brings new magnetism to MTN, ind...   \n",
       "\n",
       "                                          Brief_body  Report_Date  \\\n",
       "0  A few telecommunications network service provi...   2 days ago   \n",
       "1  MTN Nigeria’s CEO Ferdi Moolman disclosed that...       30 Jul   \n",
       "2  Claims of manipulations, irregularities and sc...       25 May   \n",
       "3  Ndukwe, the father of modern telecommunication...       16 Aug   \n",
       "\n",
       "                                            Url_link  \n",
       "0  https://guardian.ng/news/fg-orders-mtn-others-...  \n",
       "1  https://guardian.ng/news/cbn-awards-mtn-subsid...  \n",
       "2  https://guardian.ng/news/efcc-operatives-visit...  \n",
       "3  https://guardian.ng/news/ernest-ndukwe-brings-...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchKeyword = \"MTN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = f'https://edition.cnn.com/search?q={searchKeyword}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://edition.cnn.com/search?q=MTN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('Cnn.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date', 'Url_link')]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Headline = soup.find_all(\"html\")\n",
    "Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPING BBC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchKeyword = \"MTN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = f'https://www.bbc.co.uk/search?q={searchKeyword}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.bbc.co.uk/search?q=MTN'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('bbc_english.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date', 'Url_link')]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Jan 2019\n",
      "7 Sep 2018\n",
      "4 Sep 2018\n",
      "3 Oct 2019\n",
      "5 Sep 2018\n",
      "23 Feb 2017\n",
      "29 Aug 2019\n",
      "26 Aug 2019\n",
      "4 Dec 2015\n"
     ]
    }
   ],
   "source": [
    "major = soup.find_all(\"h1\", {\"itemprop\": \"headline\"})\n",
    "for i in range(len(major)):\n",
    "    \n",
    "    #Get headline\n",
    "    try:\n",
    "        Headline = soup.find_all(\"h1\", {\"itemprop\": \"headline\"})\n",
    "        Headline = Headline[i].text\n",
    "    except:\n",
    "        Headline = \"Nan\"\n",
    "    \n",
    "    #Get Date\n",
    "    try:\n",
    "        Report_Date = soup.find_all(\"li\", {\"data-result-number\": i+1})\n",
    "        Report_Date = Report_Date[0].find_all(\"time\", {\"class\": \"display-date\"})\n",
    "        Report_Date = Report_Date[0].text.strip()\n",
    "    except:\n",
    "        Report_Date = \"Nan\"\n",
    "\n",
    "    \n",
    "    #Brief Body\n",
    "    #BBC has summary long, medium and short this can be made available to the user\n",
    "    try:\n",
    "        Brief_body = soup.find_all(\"li\", {\"data-result-number\": i+1})\n",
    "        Brief_body = Brief_body[0].find_all(\"p\", {\"class\": \"summary long\"})\n",
    "        Brief_body = Brief_body[0].text.strip()\n",
    "    except:\n",
    "        Brief_body = \"Nan\"\n",
    "        \n",
    "    ##get post link\n",
    "    try:\n",
    "        link = soup.find_all(\"h1\", {\"itemprop\": \"headline\"})\n",
    "        link = link[i].a.get(\"href\")\n",
    "    except:\n",
    "        link = \"Nan\"\n",
    "    \n",
    "    entry = [(brand_name, Headline, Brief_body, Report_Date, url)]\n",
    "    #list.append(Headline_link)\n",
    "    obj.writerows(entry)\n",
    "csvfile.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('bbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Brief_body</th>\n",
       "      <th>Report_Date</th>\n",
       "      <th>Url_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Africa Live this week: MTN settlement over Nig...</td>\n",
       "      <td>…The telecommunication giant was accused of il...</td>\n",
       "      <td>6 Jan 2019</td>\n",
       "      <td>https://guardian.ng/news/ernest-ndukwe-brings-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Nigeria takes on Africa's mobile phone giant MTN</td>\n",
       "      <td>…MTN, Africa's largest mobile phone company, m...</td>\n",
       "      <td>7 Sep 2018</td>\n",
       "      <td>https://guardian.ng/news/ernest-ndukwe-brings-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Nigeria slaps $2bn bill on phone giant MTN</td>\n",
       "      <td>…Nigeria has asked mobile phone operator MTN t...</td>\n",
       "      <td>4 Sep 2018</td>\n",
       "      <td>https://guardian.ng/news/ernest-ndukwe-brings-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Nigeria and South Africa: When two African gia...</td>\n",
       "      <td>… the mobile network MTN, the supermarket chai...</td>\n",
       "      <td>3 Oct 2019</td>\n",
       "      <td>https://guardian.ng/news/ernest-ndukwe-brings-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Newsday: Nigeria Slaps MTN With Multi-billion ...</td>\n",
       "      <td>…Nigeria orders Africa's leading mobile operat...</td>\n",
       "      <td>5 Sep 2018</td>\n",
       "      <td>https://guardian.ng/news/ernest-ndukwe-brings-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand_name                                           Headline  \\\n",
       "0        MTN  Africa Live this week: MTN settlement over Nig...   \n",
       "1        MTN   Nigeria takes on Africa's mobile phone giant MTN   \n",
       "2        MTN         Nigeria slaps $2bn bill on phone giant MTN   \n",
       "3        MTN  Nigeria and South Africa: When two African gia...   \n",
       "4        MTN  Newsday: Nigeria Slaps MTN With Multi-billion ...   \n",
       "\n",
       "                                          Brief_body Report_Date  \\\n",
       "0  …The telecommunication giant was accused of il...  6 Jan 2019   \n",
       "1  …MTN, Africa's largest mobile phone company, m...  7 Sep 2018   \n",
       "2  …Nigeria has asked mobile phone operator MTN t...  4 Sep 2018   \n",
       "3  … the mobile network MTN, the supermarket chai...  3 Oct 2019   \n",
       "4  …Nigeria orders Africa's leading mobile operat...  5 Sep 2018   \n",
       "\n",
       "                                            Url_link  \n",
       "0  https://guardian.ng/news/ernest-ndukwe-brings-...  \n",
       "1  https://guardian.ng/news/ernest-ndukwe-brings-...  \n",
       "2  https://guardian.ng/news/ernest-ndukwe-brings-...  \n",
       "3  https://guardian.ng/news/ernest-ndukwe-brings-...  \n",
       "4  https://guardian.ng/news/ernest-ndukwe-brings-...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPE BBC (search tool not available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"https://www.bbc.com/yoruba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "try:\n",
    "    page = urlopen(req)\n",
    "except Exception as e: print(e)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('bbc_yoruba.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date', 'Url_link')]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "major = soup.find_all(\"h3\", {\"class\": \"Headline-sc-1dvfmi3-4 cWuUJx\"})\n",
    "for i in range(len(major)):\n",
    "    try:\n",
    "        if i == 0:\n",
    "            Headline = soup.find_all(\"h3\", {\"class\": \"Headline-sc-1dvfmi3-4 kZxQqx\"})\n",
    "            Headline = Headline[0].text\n",
    "        else:\n",
    "            Headline = soup.find_all(\"h3\", {\"class\": \"Headline-sc-1dvfmi3-4 cWuUJx\"})\n",
    "            Headline = Headline[i].text\n",
    "    except:\n",
    "        Headline = \"Nan\"\n",
    "\n",
    "       \n",
    "    try:\n",
    "        if i == 0 :\n",
    "            Report_Date = soup.find_all(\"div\", {\"class\": \"TextGridItem-sc-1dvfmi3-6 cLkEbv\"})\n",
    "            Report_Date = Report_Date[0].find_all(\"time\", {\"class\": \"StyledTimestamp-um718p-0 kVWTyt\"})\n",
    "            Report_Date = Report_Date[0].text\n",
    "        else:\n",
    "            Report_Date = soup.find_all(\"div\", {\"class\": \"TextGridItem-sc-1dvfmi3-6 fdmIIY\"})\n",
    "            Report_Date = Report_Date[i].find_all(\"time\", {\"class\": \"StyledTimestamp-um718p-0 kVWTyt\"})\n",
    "            Report_Date = Report_Date[0].text\n",
    "    except:\n",
    "        Report_Date = \"Nan\"\n",
    "        \n",
    "    try:\n",
    "        if i == 0:\n",
    "            url = soup.find_all(\"h3\", {\"class\": \"Headline-sc-1dvfmi3-4 kZxQqx\"})\n",
    "            url = url[0].a.get(\"href\")\n",
    "            url = f\"https://www.bbc.com{url}\"\n",
    "\n",
    "            req = Request(url,headers=hdr)\n",
    "            page = urlopen(req)\n",
    "            soup2 = BeautifulSoup(page)\n",
    "            \n",
    "            Brief_body = soup2.find_all(\"p\", {\"class\": \"story-body__introduction\"})\n",
    "            Brief_body = Brief_body[0].text\n",
    "        else:\n",
    "            Brief_body = soup.find_all(\"p\", {\"class\": \"Summary-sc-1dvfmi3-5 itgvLR\"})\n",
    "            Brief_body = Brief_body[i].text\n",
    "    except:\n",
    "        Brief_body = \"Nan\"\n",
    "            \n",
    "            \n",
    "    try:\n",
    "        if i == 0:\n",
    "            link = url\n",
    "        else:\n",
    "            link = soup.find_all(\"h3\", {\"class\": \"Headline-sc-1dvfmi3-4 cWuUJx\"})\n",
    "            link = link[i].a.get(\"href\")\n",
    "            link = f\"https://www.bbc.com{link}\"\n",
    "    except:\n",
    "        link = \"Nan\"\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    entry = [(\"Home\", Headline, Brief_body, Report_Date, link)]\n",
    "    #list.append(Headline_link)\n",
    "    obj.writerows(entry)\n",
    "csvfile.close()\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bbc_yoruba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Brief_body</th>\n",
       "      <th>Report_Date</th>\n",
       "      <th>Url_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Géńdé agbébọn jí adájọ́ gbé lọ ní ìpínlẹ̀ Ondo</td>\n",
       "      <td>Iroyin kan to n tẹ wa lọwọ ni yajoyajo ti ni a...</td>\n",
       "      <td>ìṣẹ́jú 46 sẹ́yìn</td>\n",
       "      <td>https://www.bbc.com/yoruba/afrika-50149498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Ọkọ mẹ́sàn-án tó forí-gbárí lórí afárá Otedola...</td>\n",
       "      <td>Àjọ tó ń rí sí ìṣẹ̀lẹ̀ pàjáwìrì ní ìpínlẹ̀ Eko...</td>\n",
       "      <td>wákàtí kan sẹ́yìn</td>\n",
       "      <td>https://www.bbc.com/yoruba/50154703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTN</td>\n",
       "      <td>A kò mọ̀ bóyá a le è san owó osù tuntun fún òs...</td>\n",
       "      <td>Ẹgbẹ́ òsìsẹ́ ni Naijiria, NLC ní oun yóò gbé ì...</td>\n",
       "      <td>ìṣẹ́jú 54 sẹ́yìn</td>\n",
       "      <td>https://www.bbc.com/yoruba/50149485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Fídíò, Ikú tó ń pa ojúgbà ẹni..., kí ni ìparí ...</td>\n",
       "      <td>BBC Yoruba fẹ mọ bi awọn ọmọ Kaarọ Oojire se g...</td>\n",
       "      <td>wákàtí 8 sẹ́yìn</td>\n",
       "      <td>https://www.bbc.com/yoruba/afrika-50149489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Bobrisky dárò pé EFCC gbé Mompha, ọ̀dọ́mọdé ol...</td>\n",
       "      <td>Orí ẹ̀rọ ayélujára ń gbóná lala láti ìgbà tí ọ...</td>\n",
       "      <td>wákàtí 6 sẹ́yìn</td>\n",
       "      <td>https://www.bbc.com/yoruba/50149479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand_name                                           Headline  \\\n",
       "0        MTN     Géńdé agbébọn jí adájọ́ gbé lọ ní ìpínlẹ̀ Ondo   \n",
       "1        MTN  Ọkọ mẹ́sàn-án tó forí-gbárí lórí afárá Otedola...   \n",
       "2        MTN  A kò mọ̀ bóyá a le è san owó osù tuntun fún òs...   \n",
       "3        MTN  Fídíò, Ikú tó ń pa ojúgbà ẹni..., kí ni ìparí ...   \n",
       "4        MTN  Bobrisky dárò pé EFCC gbé Mompha, ọ̀dọ́mọdé ol...   \n",
       "\n",
       "                                          Brief_body        Report_Date  \\\n",
       "0  Iroyin kan to n tẹ wa lọwọ ni yajoyajo ti ni a...   ìṣẹ́jú 46 sẹ́yìn   \n",
       "1  Àjọ tó ń rí sí ìṣẹ̀lẹ̀ pàjáwìrì ní ìpínlẹ̀ Eko...  wákàtí kan sẹ́yìn   \n",
       "2  Ẹgbẹ́ òsìsẹ́ ni Naijiria, NLC ní oun yóò gbé ì...   ìṣẹ́jú 54 sẹ́yìn   \n",
       "3  BBC Yoruba fẹ mọ bi awọn ọmọ Kaarọ Oojire se g...    wákàtí 8 sẹ́yìn   \n",
       "4  Orí ẹ̀rọ ayélujára ń gbóná lala láti ìgbà tí ọ...    wákàtí 6 sẹ́yìn   \n",
       "\n",
       "                                     Url_link  \n",
       "0  https://www.bbc.com/yoruba/afrika-50149498  \n",
       "1         https://www.bbc.com/yoruba/50154703  \n",
       "2         https://www.bbc.com/yoruba/50149485  \n",
       "3  https://www.bbc.com/yoruba/afrika-50149489  \n",
       "4         https://www.bbc.com/yoruba/50149479  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPE BBC HAUSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = f\"https://www.bbc.com/hausa/search/?q={searchKeyword}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "try:\n",
    "    page = urlopen(req)\n",
    "except Exception as e: print(e)\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('bbc_hausa.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date', 'Url_link')]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "major = soup.find_all(\"h3\", {\"class\": \"hard-news-unit__headline\"})\n",
    "\n",
    "for i in range(len(major)):\n",
    "    try:\n",
    "        Headline = soup.find_all(\"h3\", {\"class\": \"hard-news-unit__headline\"})\n",
    "        Headline = Headline[i].text\n",
    "        Headline\n",
    "    except:\n",
    "        Headline = \"Nan\"\n",
    "    \n",
    "    try:\n",
    "        Report_Date = soup.find_all(\"li\", {\"class\": \"mini-info-list__item\"})\n",
    "        Report_Date = Report_Date[i].text.strip()\n",
    "    except:\n",
    "        Report_Date = \"Nan\"\n",
    "        \n",
    "    try:\n",
    "        link = soup.find_all(\"h3\", {\"class\": \"hard-news-unit__headline\"})\n",
    "        link = link[i].a.get(\"href\")\n",
    "    except:\n",
    "        link = \"Nan\"\n",
    "        \n",
    "    try:\n",
    "        Brief_body = soup.find_all(\"div\", {\"class\": \"hard-news-unit hard-news-unit--regular faux-block-link\"})\n",
    "        Brief_body = Brief_body[i].find_all(\"p\", {\"class\": \"hard-news-unit__summary\"})\n",
    "        Brief_body = Brief_body[0].text\n",
    "    except:\n",
    "        Brief_body = \"Nan\"\n",
    "   \n",
    "    entry = [(brand_name, Headline, Brief_body, Report_Date, link)]\n",
    "    #list.append(Headline_link)\n",
    "    obj.writerows(entry)\n",
    "csvfile.close()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Brief_body</th>\n",
       "      <th>Report_Date</th>\n",
       "      <th>Url_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Ba kamfanonin waya ne kadai ke cinye muku data...</td>\n",
       "      <td>Mataimakin Shugaban Hukumar, Farfesa Umar Danb...</td>\n",
       "      <td>19 Oktoba 2019</td>\n",
       "      <td>https://www.bbc.co.uk/hausa/labarai-50107941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTN</td>\n",
       "      <td>MTN ya biya Najeriya kimanin N20bn</td>\n",
       "      <td>Kamfanin sadarwa na MTN ya sasanta da babban b...</td>\n",
       "      <td>25 Disamba 2018</td>\n",
       "      <td>https://www.bbc.co.uk/hausa/labarai-46676888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Gwamnatin Najeriya da MTN sun cimma matsaya</td>\n",
       "      <td>Gwamnatin Najeriya da kamfanin sadarwa na MTN ...</td>\n",
       "      <td>11 Janairu 2019</td>\n",
       "      <td>https://www.bbc.co.uk/hausa/labarai-46839435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Najeriya ta 'kakaba' wa MTN harajin biliyan 612</td>\n",
       "      <td>Wannan na zuwa ne yayin da MTN ya yi zargin ce...</td>\n",
       "      <td>4 Satumba 2018</td>\n",
       "      <td>https://www.bbc.co.uk/hausa/labarai-45411003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTN</td>\n",
       "      <td>Babban bankin Najeriya CBN ya ci tarar bankuna...</td>\n",
       "      <td>CBN dai ya ce ya dauki wannan matakin ne bayan...</td>\n",
       "      <td>30 Agusta 2018</td>\n",
       "      <td>https://www.bbc.co.uk/hausa/labarai-45356436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand_name                                           Headline  \\\n",
       "0        MTN  Ba kamfanonin waya ne kadai ke cinye muku data...   \n",
       "1        MTN                 MTN ya biya Najeriya kimanin N20bn   \n",
       "2        MTN        Gwamnatin Najeriya da MTN sun cimma matsaya   \n",
       "3        MTN    Najeriya ta 'kakaba' wa MTN harajin biliyan 612   \n",
       "4        MTN  Babban bankin Najeriya CBN ya ci tarar bankuna...   \n",
       "\n",
       "                                          Brief_body      Report_Date  \\\n",
       "0  Mataimakin Shugaban Hukumar, Farfesa Umar Danb...   19 Oktoba 2019   \n",
       "1  Kamfanin sadarwa na MTN ya sasanta da babban b...  25 Disamba 2018   \n",
       "2  Gwamnatin Najeriya da kamfanin sadarwa na MTN ...  11 Janairu 2019   \n",
       "3  Wannan na zuwa ne yayin da MTN ya yi zargin ce...   4 Satumba 2018   \n",
       "4  CBN dai ya ce ya dauki wannan matakin ne bayan...   30 Agusta 2018   \n",
       "\n",
       "                                       Url_link  \n",
       "0  https://www.bbc.co.uk/hausa/labarai-50107941  \n",
       "1  https://www.bbc.co.uk/hausa/labarai-46676888  \n",
       "2  https://www.bbc.co.uk/hausa/labarai-46839435  \n",
       "3  https://www.bbc.co.uk/hausa/labarai-45411003  \n",
       "4  https://www.bbc.co.uk/hausa/labarai-45356436  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bbc_hausa.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPE LINDA IKEJIS BLOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"https://www.lindaikejisblog.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(site,headers=hdr)\n",
    "try:\n",
    "    page = urlopen(req)\n",
    "except Exception as e: print(e)\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = open('lindaikeji_blog.csv','w', newline='')\n",
    "obj = csv.writer(csvfile)\n",
    "headers=[('Brand_name', 'Headline', 'Brief_body', 'Report_Date', 'Url_link', \"comment_dict\")]\n",
    "obj.writerows(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "{'username': 'comments'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-384-7ce469398e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full Page Search\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeadline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBrief_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReport_Date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m#list.append(Headline_link)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "major = soup.find_all(\"h1\", {\"class\": \"story_title\"})\n",
    "comment_dict = {\"username\" : \"comments\"}\n",
    "\n",
    "for i in range(len(major)):\n",
    "    try:\n",
    "        Headline = soup.find_all(\"h1\", {\"class\": \"story_title\"})\n",
    "        Headline = Headline[i].text\n",
    "        Headline\n",
    "    except:\n",
    "        Headline = \"Nan\"\n",
    "        \n",
    "   \n",
    "    try:\n",
    "        pattern = re.compile(r'\\n\\xa0\\n')\n",
    "\n",
    "        Brief_body = soup.find_all(\"p\", {\"class\": \"story_description\"})\n",
    "        Brief_body = Brief_body[i].text.strip()\n",
    "        Brief_body = pattern.sub('', Brief_body)\n",
    "    except:\n",
    "        Headline = \"Nan\"\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        patternDate = re.compile(r'by Linda Ikeji at ')\n",
    "\n",
    "        Report_Date = soup.find_all(\"div\", {\"class\": \"post_age\"})\n",
    "        Report_Date = Report_Date[i].text.strip()\n",
    "        Report_Date = patternDate.sub('', Report_Date )\n",
    "    except:\n",
    "        Report_Date = \"Nan\"\n",
    "        \n",
    "    try:\n",
    "        link = soup.find_all(\"div\", {\"class\": \"col-xs-12 col-sm-6 col-md-6\"})\n",
    "        link = link[i].a.get(\"href\")\n",
    "    except:\n",
    "        link = \"Nan\"\n",
    "        \n",
    "    #get comments into a dictionary\n",
    "    \n",
    "    #create post page soup \n",
    "    if link != \"Nan\":\n",
    "        req = Request(link,headers=hdr)\n",
    "        try:\n",
    "            page = urlopen(req)\n",
    "        except Exception as e: print(e)\n",
    "    \n",
    "        soup_comment = BeautifulSoup(page)\n",
    "    \n",
    "        iterator = soup_comment.find_all(\"div\", {\"class\": \"comment_holder\"})\n",
    "        \n",
    "        if(len(iterator)) != 0:\n",
    "            for j in range(len(iterator)):\n",
    "                username = soup_comment.find_all(\"div\", {\"class\": \"comment_holder\"})\n",
    "                username = username[j].find_all(\"a\", {\"class\": \"profile_name\"})\n",
    "                username = username[0].text\n",
    "            \n",
    "                comment = soup_comment.find_all(\"div\", {\"class\": \"comment_holder\"})\n",
    "                comment = comment[j].find_all(\"p\", {\"style\": \"font-size: 16px; margin-top: 6px;\"})\n",
    "                comment = comment[0].text.strip()\n",
    "            \n",
    "                comment_dict[username] = comment\n",
    "        print(comment_dict)\n",
    "    else:\n",
    "        comment_dict = {\"Nan\" : \"Nan\"}\n",
    "            \n",
    "            \n",
    "    entry = [(\"Full Page Search\", Headline, Brief_body, Report_Date, link, comment_dict)]\n",
    "    #list.append(Headline_link)\n",
    "    obj.writerows(entry)\n",
    "csvfile.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Brief_body</th>\n",
       "      <th>Report_Date</th>\n",
       "      <th>Url_link</th>\n",
       "      <th>comment_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full Page Search</td>\n",
       "      <td>Davido offers N1m to anybody who can find th...</td>\n",
       "      <td>Davido has offered to give N1 million to anyon...</td>\n",
       "      <td>23/10/19</td>\n",
       "      <td>https://www.lindaikejisblog.com/2019/10/davido...</td>\n",
       "      <td>{'username': 'comments'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Page Search</td>\n",
       "      <td>Seems 'Power' star, Rotimi and Vanessa Mdee ...</td>\n",
       "      <td>It seems Nigerian-born American actor and 'Pow...</td>\n",
       "      <td>23/10/19</td>\n",
       "      <td>https://www.lindaikejisblog.com/2019/10/seems-...</td>\n",
       "      <td>{'username': 'comments'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Page Search</td>\n",
       "      <td>Over 30 months after, jailed Nigerian filmma...</td>\n",
       "      <td>Controversial Yoruba filmmaker, Seun Egbegbe, ...</td>\n",
       "      <td>23/10/19</td>\n",
       "      <td>https://www.lindaikejisblog.com/2019/10/over-3...</td>\n",
       "      <td>{'username': 'comments'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full Page Search</td>\n",
       "      <td>Veteran actor and broadcaster, Sadiq Daba is...</td>\n",
       "      <td>Ace broadcaster and veteran actor, Sadiq Daba ...</td>\n",
       "      <td>23/10/19</td>\n",
       "      <td>https://www.lindaikejisblog.com/2019/10/vetera...</td>\n",
       "      <td>{'username': 'comments', 'emmanuel ohio': 'Nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Page Search</td>\n",
       "      <td>Gunmen abduct High court judge, demand N50m ...</td>\n",
       "      <td>Abdul Dogo, a judge of the Federal High Court ...</td>\n",
       "      <td>23/10/19</td>\n",
       "      <td>https://www.lindaikejisblog.com/2019/10/gunmen...</td>\n",
       "      <td>{'username': 'comments', 'Anonymous': 'Ok na t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand_name                                           Headline  \\\n",
       "0  Full Page Search    Davido offers N1m to anybody who can find th...   \n",
       "1  Full Page Search    Seems 'Power' star, Rotimi and Vanessa Mdee ...   \n",
       "2  Full Page Search    Over 30 months after, jailed Nigerian filmma...   \n",
       "3  Full Page Search    Veteran actor and broadcaster, Sadiq Daba is...   \n",
       "4  Full Page Search    Gunmen abduct High court judge, demand N50m ...   \n",
       "\n",
       "                                          Brief_body Report_Date  \\\n",
       "0  Davido has offered to give N1 million to anyon...    23/10/19   \n",
       "1  It seems Nigerian-born American actor and 'Pow...    23/10/19   \n",
       "2  Controversial Yoruba filmmaker, Seun Egbegbe, ...    23/10/19   \n",
       "3  Ace broadcaster and veteran actor, Sadiq Daba ...    23/10/19   \n",
       "4  Abdul Dogo, a judge of the Federal High Court ...    23/10/19   \n",
       "\n",
       "                                            Url_link  \\\n",
       "0  https://www.lindaikejisblog.com/2019/10/davido...   \n",
       "1  https://www.lindaikejisblog.com/2019/10/seems-...   \n",
       "2  https://www.lindaikejisblog.com/2019/10/over-3...   \n",
       "3  https://www.lindaikejisblog.com/2019/10/vetera...   \n",
       "4  https://www.lindaikejisblog.com/2019/10/gunmen...   \n",
       "\n",
       "                                        comment_dict  \n",
       "0                           {'username': 'comments'}  \n",
       "1                           {'username': 'comments'}  \n",
       "2                           {'username': 'comments'}  \n",
       "3  {'username': 'comments', 'emmanuel ohio': 'Nor...  \n",
       "4  {'username': 'comments', 'Anonymous': 'Ok na t...  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lindaikeji_blog.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"https://www.lindaikejisblog.com/2019/10/every-parents-worst-nightmare-nanny-arrested-in-south-africa-for-allegedly-strangling-toddler-to-death.html\"\n",
    "req = Request(site,headers=hdr)\n",
    "try:\n",
    "    page = urlopen(req)\n",
    "except Exception as e: print(e)\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nkiru MBA'"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Headline = soup.find_all(\"div\", {\"class\": \"comment_holder\"})\n",
    "Headline = Headline[3].find_all(\"a\", {\"class\": \"profile_name\"})\n",
    "Headline = Headline[0].text\n",
    "Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Terrible people everywhere... dee'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Headline = soup.find_all(\"div\", {\"class\": \"comment_holder\"})\n",
    "Headline = Headline[0].find_all(\"p\", {\"style\": \"font-size: 16px; margin-top: 6px;\"})\n",
    "Headline = Headline[0].text.strip()\n",
    "Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
